# Глава 1. Знакомьтесь: Kafka 
В общем, это вводная глава в которой рассказывается о истории появления данного брокера сообщений, и о основных понятиях:
- обмен по типу "публикация/подписка"
    Паттерн "обмен сообщениями по типу публикация / подписка" отличается тем, что производителя сообщения не направляет его конкретному потребителю. Вместо этого он классифицирует сообщения, а потребитель подписывается на определенные классы. Для упрощения взаимодействия, между отправителем и получателем, вводится брокер.
- сообщение (message)
    Единица данных. Для kafka представляет собой просто массив байтов. В сообщение могут быль включены дополнительные метаданные, в том числе ключ, который используется для выбора раздела записи сообщения.
- пакет (batch)
    Для повышения эффективности сообщения от производителя и к потребителю отправляются не по одному, а в пакетах. Пакеты могут дополнительно сжиматься
- схемы
    Сообщения внутри kafka хранятся как набор байт, но рекомендуется придерживаться выбранной схемы для производителя и потребителя, в форматах JSON или XML. В книге рекомендуется использовать фреймворк Apache Avro
- топики (topics)
    Сообщения разделяются по топикам (topics). Это некоторое логическое разделение сообщений во которому производители могут писать, а потребители читать
-  разделы (partition)
    Топики разбиваются на разделы (partiton). Это разделение позволяет массштабировать нагрузку горизонтально. При этом производители могут выбирать в какие разделы и какие сообщения писать. А потребители в составе групп делить разделы для обработки. Сообщения в одном разделе всегда упорядочены по времени поступления. Но их порядок не гарантируется в объеме всего топика. Кроме этого разделы могут быть реплецированны, то есть могут быть созданы дубликаты для повышения надежности в случае выхода из строя одного из брокеров.
- производители (producers)
    Создают сообщения и отправляют их в определенный топик. Могут отправлять сообщения в определенный раздел, например исходя из значения ключа
- потребители (consumers)
    Читают сообщения из одного или нескольких топиков. И читает их в порядке хранения в разделе. При этом потребитель может останавливаться и при возобновлении работы продолжать читать с того мета в котором остановился
- группы потребителей (consumers groups)
    Потребители можно объединять в группы, в этом случае потребители будут равномерно разделены между разделами одного топика. Это позволяет горизонтально масштабировать потребителей.
- брокер (broker)
    Это отдельный сервер kafka. Он получает сообщения от производителей, присваивает им смещения и сохраняет. Обслуживает потребителей, отвечая на запросы получения сообщений.
- кластер (cluster)
    Брокеры можно объединять в кластеры. В этом случае разделы и реплецированные разделы топиков будут равномерно распределяться между брокерами.
- контроллер кластера (cluster controller)
    В случае организации брокеров в единый кластер, один из брокеров выбирается в качестве контроллера. Он отвечает за административные операции, такие как распределение разделов и мониторинг отказов.
- ведущий раздел (leader)
    В случае репликации разделов один из них, на одном из брокеров будет выбран как ведущий. Вся работа с производителями и потребителями будет производится только через него
- раздел последователь (followers)
    В случае репликации разделов помимо ведущего раздела будут созданы разделы последователи. Производители и потребители с ними не работают, в них только дублируются данные из ведущего раздела. В случает отказа брокера с ведущим разделом, один из последователей возьмет на себя эту роль
- Время сохранения информации (retention)
    В настройках брокера можно настроить, сколько по времени информация в нем будет храниться, либо ограничить размер сохраняемой информации.

Так же в главе кратко поднимается вопрос нескольких кластеров и настройки взаимодействия между ними. 
Описываются преимущества kafka перед другими брокерами сообщений. Называются следующие преимущества:
- несколько производителей - возможно работа нескольких производителей на разные топики или на один общий топик.
- несколько потребителей - возможно работа нескольких потребителей с одним топиком, с возможность распаралеливания нагрузки.
- сохранение информации на диске - все сообщения хранятся на диске, что увеличивает надежность и не требует от потребителей немедленной обработки сообщений.
- масштабируемость - возможность собирать брокеры в кластер и масштабировать нагрузку горизонтально.
- высокое быстродействие - подход публикация/подписка с минимальной логикой на стороне брокера. Так же высокое быстродействие обеспечивается горизонтальным масштабированием.
Дополнительно предлагаются самые частые сценарии использования:
- отслеживание действий пользователя;
- обмен сообщениями;
- журналлирование - собираются данные некоторого приложения;
- журнал фиксации - сохраняются изменения в некоторой системе (например в БД) с последующей возможность восстановления;
- потоковая обработка.

# Глава 2. Установка Kafka
В данной главе описывается порядок установки kafka, его окружения из java и ZooKeeper и их настройки.
В начале рассказывается о том как настроить ZooKeeper, о ансамбле, и о параметрах необходимых для его запуска.
Дальше рассказывается об установке брокера kafka, тестовом создании топика, отправку и получении из него сообщений.
Далее перечисляются параметры настроек брокера используемой в файле конфигурации. Такие как:
- идентификатор брокера внутри кластера;
- подключение к ZooKeeper;
- включение автоматического создания топика;
- настройка количества партиций и репликаций.
и так далее....
Так же рассказывается о приоритетах для выбираемого железа, на котором будет работать кластер. Особо выделяется важность скорости и объема жестких дисков, доступной оперативной памяти и скорости сети, и в меньшей степени скорости процессора.
Небольшое внимание уделяется работе kafka в облачной среде.
Даются советы по ориентировочным оценке требуемого оборудования от количества разделов, конфигурирование операционной системы, настройке гарбедж коллектора, и размещению серверов в ЦОД.

# Глава 3. Производители Kafka: запись сообщений в Kafka
В этой главе рассказывается о работе и настройке производителей. 
Производитель может быть настроен для реализации различных сценариев. Как для сценария с высокой критичностью к потере сообщений и высокой производительностью, так и в сценариях при которых потеря части сообщений не критична но важна экономия ресурсов. Возможны сценарии при которых порядок сообщений критический важен, так и порядок не так важен как производительность.

Процесс отправки сообщения следующий:
- создается производитель с определенной конфигурацией
- создается запись (record) для отправки, включающая в себя топик, раздел, ключ и значение
- вызывается метод send на производителе
- ключ и значение сериализуются
- если не указан раздел, то вызывается partitioner и раздел выбирается
- сообщение складывается в пакет и ожидает своей отправки
- если отправка прошла не успешно, то отправка будет выполнена повторно сконфигурированное число раз
- в случае успешной отправки брокер вернет объект RecordMetadata с указанием топика, раздела и смещения
При этом метод send может бросать ошибку, если не удалось что-то сделать еще до того как сообщение попадает в пакет. Например, если не удалось сериализовать сообщение или буфер сообщений переполнен.

При создании производителя у него есть несколько обязательных параметров:
- список брокеров в виде пар host:port (bootstrap.servers). Для кластера рекомендуется указывать как минимум два брокера, для гарантии того, что производитель сможет подключится хотя бы к одному в случае выхода другого из строя
- класс сериализации ключа (key.serializer). В котором будет указан формат ключа и класс для преобразования его в набор байт
- класс сериализации значений (value.serializer). В котором будет указан формат значения и класс для преобразования значения.
Кроме этих параметров есть и другие настройки, такие как должен ли брокер возвращать ответ и когда он должен это делать (acks), время ожидания брокера, размер кэша, количество попыток и другие.

При отправке сообщения, брокер возвращает ответ с названием топика, раздел и смещение. Ответа можно не дожидаться, дожидаться синхронно или асинхронно.

Производитель можно настроить на разные режимы приемы ответа от брокера (acks). Для настройки производителя необходимо использовать ключ acks (String ACKS_CONFIG). Это настройка может принимать следующие параметры:
- 0 - если ответа от брокера не требуется. При попытке обработать сообщение в нем будет указан нулевой раздел и смещение равное -1
- 1 - ответ будет возвращен после сохранения сообщения в лидере
- all (-1) - ответ будет возвращен после сохранения в лидере и последователях с обязательным сохранением
Эта настройка влияет на производительность, и на надежность доставки сообщений.

Время отправки сообщения складывается из нескольких этапов. 
- время работы метода send() (max.block.ms), может быль задано максимальное значение в которое так же входит получение метаданных от брокера. 
- время ожидания при сборке пакета (linger.ms)
- время доставки (delivery.timeout.ms), которое складывается из суммарного времени между попытками отправки если они понадобились (retry.backoff.ms) и временем отправки (request.timeout.ms)

В библиотеке kafka уже имеются готовые сериализаторы для примитивных типов, как строки или числа. Имеется возможность создать свой сериализатор реализовав интерфейс Serializer. И указав его в настройках производителя. 
Кроме реализованных сериализаторов есть возможность использовать библиотеки сериализации, такие как JSON, Apache Avro, Thrigh, Protobuf.

Выбор раздела в который будет отправлено сообщение по умолчанию использует хэш ключа. Но возможны и другие сценарии выбора раздела:
- циклический алгоритм (RoundRobinParitioner), выбирается если ключ пустой. Каждое следующее сообщение отправляется в следующий раздел
- "липкий" циклический режим (UniformStickyPartitioner). В следующий раздел отправляется не отдельное сообщение, а пакет из сообщений.
- раздел выбирается в зависимости от ключа, номер задела высчитывается путем целочисленного деления на количество разделов. Это режим используется по умолчанию
Кроме этого можно реализовать свой алгоритм выбора раздела реализовав интерфейс partitioner. Это может пригодится, например при балансировке, если алгоритм по ключу не дает качественного результата. Например если в качестве ключа используется идентификатор клиента, и один клиент создает нагрузку заметно большую чем другие клиенты.

Заголовки в сообщении это дополнительные метаданные, которые передаются вместе с сообщением. Выглядят как ключ значение, где ключ строка, а значение набор байт. Добавить заголовок в сообщение можно следующим образом:
record.headers().add("key", new bytes\[\]);

Сквозной функционал в передачу сообщения и в прием ответов можно использую перехватчики (Intercepter). Перехватчики можно использовать для логирования, или для модификации сообщений. Для этого необходимо реализовать интерфейс ProducerIntercepter, и методы в нем onSend для работы с отправляемыми сообщениями, и метод onAcknowledgement для работы с ответами. Перехватчик необходимо добавить в конфигурацию производителя используя ключ interceptor.classes (ProducerConfig.INTERCEPTOR_CLASSES_CONFIG) и пакет и имя класса в качестве значения. Так же перехватчик можно добавить в уже собранный проект.

Так же на стороне брокера можно настраивать квоты на производителя на ограничение приема сообщений. Защищая брокер от слишком большого потока сообщений.

